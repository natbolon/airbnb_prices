{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airbnb NYC 2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import Ridge, ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "mpl.rcParams['font.size'] = 12\n",
    "mpl.rcParams['axes.labelsize'] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration\n",
    "Load data and perform first exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb = pd.read_csv('./Data/AB_NYC_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of entries: {} \\nNumber of features: {}'.format(df_airbnb.shape[0], df_airbnb.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A first look suggests that columns such as **id**, **name**, **host_id** and **host_name** can be discarded from the analysis. \n",
    "\n",
    "The column **name** could be used to incorporate some more features (keywords appearing in the name). This will be discarded on the first simple models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop features id, host_id and host_name\n",
    "df_airbnb.drop(['id', 'name', 'host_name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will look for missing data on the remaining features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have missing data for the following features:\n",
    "* last_review --> comes from entries without any review\n",
    "* reviews_per_month --> comes from entries without any review; we will replace it by 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â replace NaN by 0 for column reviews per month\n",
    "df_airbnb.reviews_per_month.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have 12 columns, 11 of them corresponding to features and 1 corresponding to our target variable, price. \n",
    "\n",
    "First we will start by taking a look to the price to see its distribution and check there are no inconsistencies.\n",
    "\n",
    "Then we will explore the features and their distributions and correlation among them. We can expect high correlation between:\n",
    "* neighbourhood_group, neighbourhood, latitude and longitude\n",
    "* number_of_reviews and reviews_per_month (can also be related with last_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "df_airbnb['price'].plot(kind='hist', bins=80, title='Price distribution', ax=ax[0])\n",
    "df_airbnb['price'].plot(kind='hist', bins=80,logx=True, logy=True, title='Price distribution', ax=ax[1])\n",
    "ax[0].set_xlabel('Price $')\n",
    "ax[1].set_xlabel('Log Price $')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb['price'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of cases with price = $0: ',len(df_airbnb[df_airbnb.price == 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop cases with price 0\n",
    "df_airbnb.drop(df_airbnb[df_airbnb.price < 10]. index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pct_price(attribute, value):\n",
    "    print('Appartments with {} over ${}: {:.2f}%'.\\\n",
    "          format(attribute, \\\n",
    "                 value, \\\n",
    "                 100 * len(df_airbnb[df_airbnb[attribute] > value])/len(df_airbnb)))\n",
    "\n",
    "print_pct_price('price', 200)\n",
    "print_pct_price('price', 300)\n",
    "print_pct_price('price', 500)\n",
    "print_pct_price('price', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "df_airbnb[df_airbnb['price'] <= 400].price.plot(kind='hist', bins=100,title='Price distribution below $300', ax=ax[0])\n",
    "df_airbnb[df_airbnb['price'] > 400].price.plot(kind='hist', bins=100, title='Price distribution above $300', ax=ax[1])\n",
    "ax[0].set_xlabel('Price $')\n",
    "ax[1].set_xlabel('Price $')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights: \n",
    "* Mean price is \\\\$153 and median price is \\\\$106. This reflects large outliers that increase the mean price.\n",
    "* Min price is \\\\$0 while max price is \\\\$10k. We will drop the cases with price = \\\\$0 since they may correspond to errors.\n",
    "* Around 95% of the appartments have a price lower than \\\\$300. From these, a good amount concentrate in a range lower than \\\\$100. We can also observe some peaks around round prices (100, 150, etc.)\n",
    "* Appartments over \\\\$1k represent less than 0.5\\% of the cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration of features\n",
    "\n",
    "The features **neighbourhood** is left out of the plot due to the large number of possible values. The feature **last_review** is left out of the plot since we cannot relate it to the date when the prices were retrieved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(3,3, figsize=(40,30))\n",
    "ax = ax.flatten()\n",
    "for idx, col in enumerate(df_airbnb.drop(['neighbourhood', 'price', 'last_review'], axis=1).columns):\n",
    "    if df_airbnb[col].dtype == object:\n",
    "        df_airbnb.groupby(col).count().iloc[:,1].plot(kind='bar', ax=ax[idx], title=col)\n",
    "        ax[idx].tick_params(axis='x', rotation=0)\n",
    "    else:\n",
    "        df_airbnb[col].plot(kind='hist', bins=50, ax=ax[idx], title=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights: \n",
    "* Neighbourhood: Brooklyn and Manhattan are the most represented ones.\n",
    "* Most locations offered are entire appartments or private rooms. Shared rooms are very rare.\n",
    "* Number of reviews and reviews per month seem to follow a Poisson distribution.\n",
    "* Minimum nights and host listing count may offer more insights when taking logarithm of the values. \n",
    "* Availability is highly concentrated aroud 1 and then there is a great decrease for the rest of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis per neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb.groupby('neighbourhood_group').agg({'neighbourhood':['count','nunique'], \n",
    "                                              'price':['min', 'mean', 'median', 'max'],\n",
    "                                             'number_of_reviews':['min', 'mean', 'median', 'max']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we analyse by neighbourhood, we can highlight:\n",
    "* Manhattan is the one grouping less neighbourhoods with around 60% of the neighbourhoods that Queens groups (which is the one with the largest value).\n",
    "* In terms of price, they all have almost the same minimum price. Nevertheless, Manhattan shows a median price that is almost 3 times the median of the lowest price (Bronx). The maximum price at Bronx is 25% of the maximum at Manhattan, Brooklyn and Staten Island. \n",
    "* In terms of number of reviews, the median is much lower than the mean in all cases, showing the presence of large sporadic numbers and a great amount of low values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_price_dist(col_name):\n",
    "    f, ax = plt.subplots(1,2, figsize=(20,5))\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    sns.violinplot(data=df_airbnb[df_airbnb.price < 350], x=col_name, y='price', ax=ax[0])\n",
    "    sns.violinplot(data=df_airbnb, x=col_name, y='price', ax=ax[1])\n",
    "    ax[0].set_title('Price (up to $350) vs {}'.format(col_name))\n",
    "    ax[1].set_title('Price vs {}'.format(col_name))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_price_dist('neighbourhood_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis type of room"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb.groupby('room_type').agg({'price':['min', 'mean', 'median', 'max'],\n",
    "                                    'number_of_reviews':['min', 'mean', 'median', 'max']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_price_dist('room_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the type of room, we can highlight:\n",
    "* Private and Share rooms have a similar mean price but private rooms can increase to much higher prices ( \\\\$10k vs \\\\$1.8k) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis reviews\n",
    "The columns **last review** does not offer us much data since this value is static and we cannot relate it to the current date (the data has not been updated and we don't know the day when it was generated). Therefore, we will not consider it. \n",
    "\n",
    "We expect high correlation between **number of reviews** and **reviews per month**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb.drop(['last_review'], axis=1, inplace=True)\n",
    "df_airbnb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20,5))\n",
    "df_airbnb.plot(kind='scatter', x='number_of_reviews', y='reviews_per_month', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1,2,figsize=(20,5))\n",
    "df_airbnb.plot(kind='scatter', x='number_of_reviews', y='price', \\\n",
    "               ax=ax[0], title='Price vs Number of Reviews')\n",
    "df_airbnb.plot(kind='scatter', x='reviews_per_month', y='price', \\\n",
    "               ax=ax[1], title='Price vs Reviews/Month')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights from reviews:\n",
    "* Number of reviews and reviews per month are correlated although less than expected. The relation is bounded. \n",
    "* The relation with price shows an exponential decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation between features and encoding of categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â drop neighbourhood prioritizing neighbourhood group\n",
    "df_airbnb.drop(['neighbourhood'], axis=1, inplace=True)\n",
    "# transform categorical variables to 1-hot encoding\n",
    "df_airbnb_encoded = pd.get_dummies(df_airbnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corr = np.corrcoef(df_airbnb_encoded.transpose()).round(decimals=3)\n",
    "#fig, ax = plt.subplots(figsize=(20,20))\n",
    "#sns.heatmap(corr, vmin=-1, vmax=1, annot=True, ax=ax, \\\n",
    "#            xticklabels=df_airbnb_encoded.columns, yticklabels=df_airbnb_encoded.columns)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Prediction:\n",
    "\n",
    "* Create train and test set\n",
    "* Normalize features\n",
    "* For different models:\n",
    "    - Train, tune hyperparameters, evaluate performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_outliers = df_airbnb_encoded.drop(df_airbnb_encoded[df_airbnb_encoded['price'] > 350].index, axis=0)\n",
    "#df_outliers = df_airbnb_encoded\n",
    "X, y = df_outliers.drop(['price'], axis=1), df_outliers.price\n",
    "\n",
    "# Split data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#Â scale features\n",
    "# Not using StandardScaler to treat differently continuous, discrete and categorical variables\n",
    "\n",
    "def scale(x, df_train, df_test, cont=True):\n",
    "    std = np.std(df_train[x])\n",
    "\n",
    "    if cont:\n",
    "        mean = np.mean(df_train[x])\n",
    "        df_train[x] = df_train[x].apply(lambda x: (x - mean)/std)\n",
    "        df_test[x] = df_test[x].apply(lambda x: (x - mean)/std)\n",
    "    else:\n",
    "        median = np.median(df_train[x])\n",
    "        df_train[x] = df_train[x].apply(lambda x: (x - median)/std)\n",
    "        df_test[x] = df_test[x].apply(lambda x: (x - median)/std)\n",
    "\n",
    "\n",
    "X_train_transformed = X_train.copy()\n",
    "X_test_transformed = X_test.copy()\n",
    "\n",
    "for feature in ['latitude', 'longitude', 'reviews_per_month']:\n",
    "    scale(feature, X_train_transformed, X_test_transformed)\n",
    "\n",
    "\n",
    "for feature in ['minimum_nights', 'number_of_reviews', 'calculated_host_listings_count', 'availability_365']:\n",
    "    scale(feature, X_train_transformed, X_test_transformed, cont=False)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y_pred, y_true):\n",
    "    print('RMSE: {:.4f}'.format(mean_squared_error(y_true, y_pred, squared=False)))\n",
    "    print('MAE : {:.4f}'.format(mean_absolute_error(y_true, y_pred)))\n",
    "    print('R2  : {:.4f}'.format(r2_score(y_true, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_outliers = y_train <= 350"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1. Ridge Regression --REVIEW!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = np.logspace(-3, 3, 40)\n",
    "\n",
    "model1 = Ridge()\n",
    "grid1 = GridSearchCV(estimator=model1, param_grid=dict(alpha=params1), cv=5)\n",
    "grid1.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred1 = grid1.predict(X_test_transformed)\n",
    "get_score(y_pred1, y_test)\n",
    "print(grid1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2. Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params2 = {'alpha':np.logspace(-2, 2, 10), 'l1_ratio':np.linspace(1e-2, 1, 10)}\n",
    "\n",
    "model2 = ElasticNet(max_iter=100)\n",
    "grid2 = GridSearchCV(estimator=model2, param_grid=params2, cv=5)\n",
    "grid2.fit(X_train_transformed, y_train)\n",
    "\n",
    "y_pred2 = grid2.predict(X_test_transformed)\n",
    "get_score(y_pred2, y_test)\n",
    "print(grid2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3. Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params3 = {'max_depth': range(3,7), 'n_estimators': (10, 50, 100, 1000)}\n",
    "\n",
    "model3 = RandomForestRegressor()\n",
    "grid3 = GridSearchCV(estimator=model3, param_grid=params3, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "grid_result = grid3.fit(X, y)\n",
    "best_params = grid_result.best_params_\n",
    "\n",
    "model3_best = RandomForestRegressor(max_depth=best_params[\"max_depth\"], n_estimators=best_params[\"n_estimators\"],\n",
    "                                random_state=False, verbose=False)\n",
    "model3_best.fit(X_train_transformed, y_train)\n",
    "y_pred3 = model3_best.predict(X_test_transformed)\n",
    "get_score(y_pred3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('best_parameters: ', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params4 = [{'hidden_layer_sizes': [10,30,50, 100],\n",
    "'activation': ['relu'],\n",
    "'solver':['lbfgs'], 'alpha':[5e-1, 1e-2, 1e-3, 1e-4],\n",
    "'batch_size':['auto'], \n",
    "'learning_rate_init':[1e-3], 'max_iter':[500]}]\n",
    "\n",
    "model4 = MLPRegressor(verbose=True)\n",
    "grid4 = GridSearchCV(model4, params4, cv=5)\n",
    "grid_result = grid4.fit(X_train_transformed, y_train)\n",
    " \n",
    "#mlp = MLPRegressor(hidden_layer_sizes=(20,), activation='logistic', solver='lbfgs', alpha=0.0001, batch_size='auto', learning_rate='constant', learning_rate_init=0.001, max_iter=500)\n",
    "#mlp.fit(X_train,y_train)\n",
    "train_mse = mean_squared_error(y_train, grid4.predict(X_train_transformed))\n",
    "test_mse = mean_squared_error(y_test, grid4.predict(X_test_transformed))\n",
    "\n",
    "y_pred4 = grid4.predict(X_test_transformed)\n",
    "get_score(y_pred4, y_test)\n",
    " \n",
    "print(grid4.best_params_)\n",
    "print(grid4.best_score_)\n",
    "print(\"Train MSE:\", np.round(train_mse,2))\n",
    "print(\"Test MSE:\", np.round(test_mse,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,5))\n",
    "def error(y, y_pred):\n",
    "    return np.sqrt((y - y_pred)**2)\n",
    "\n",
    "plt.hist(error(y_test, y_pred1), bins=100, color='blue', alpha=0.5)\n",
    "plt.hist(error(y_test, y_pred2), bins=100, color='red', alpha=0.5)\n",
    "plt.hist(error(y_test, y_pred3), bins=100, color='green', alpha=0.5)\n",
    "plt.hist(error(y_test, y_pred4), bins=100, color='black', alpha=0.2)\n",
    "plt.legend(['Ridge', 'ElasticNet', 'RandomForest', 'MLP'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
